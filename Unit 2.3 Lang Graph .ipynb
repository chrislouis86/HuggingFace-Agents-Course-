{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6301ced1-eb47-40ea-acbb-2eb1f9fbed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State \n",
    "\n",
    "from typing_extensions  import TypedDict \n",
    "\n",
    "class State(TypedDict):\n",
    "    graph_state: str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ab5ce51-5ff9-40bb-b557-d2fd22f0ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node \n",
    "\n",
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" I am\"}\n",
    "\n",
    "def node_2(state):\n",
    "    print(\"---Node 2---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" happy!\"}\n",
    "\n",
    "def node_3(state):\n",
    "    print(\"---Node 3---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" sad!\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3567f8e-50d0-4982-8d51-b787561e6a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edges \n",
    "\n",
    "import random\n",
    "from typing import Literal\n",
    "\n",
    "def decide_mood(state) -> Literal[\"node_2\", \"node_3\"]:\n",
    "    \n",
    "    # Often, we will use state to decide on the next node to visit\n",
    "    user_input = state['graph_state'] \n",
    "    \n",
    "    # Here, let's just do a 50 / 50 split between nodes 2, 3\n",
    "    if random.random() < 0.5:\n",
    "\n",
    "        # 50% of the time, we return Node 2\n",
    "        return \"node_2\"\n",
    "    \n",
    "    # 50% of the time, we return Node 3\n",
    "    return \"node_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d613fbcf-0fde-4b1e-a45f-67cc420a3ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StateGraph \n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_conditional_edges(\"node_1\", decide_mood)\n",
    "builder.add_edge(\"node_2\", END)\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9493e0a3-cddb-4d04-92ce-d61fb19a73a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47350cda-ef39-4bec-b58b-4fae2280ed8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n",
      "---Node 2---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'graph_state': 'Hi, this is Lance. I am happy!'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"graph_state\" : \"Hi, this is Lance.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20df08db-44ac-444a-afdb-b2df84a5379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71fed7ad-4eac-4b44-bb1d-30893ac1a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define Our State\n",
    "class EmailState(TypedDict):\n",
    "    # The email being processed\n",
    "    email: Dict[str, Any]  # Contains subject, sender, body, etc.\n",
    "\n",
    "    # Category of the email\n",
    "    email_category: Optional[str]\n",
    "    \n",
    "    # Analysis and decisions\n",
    "    is_spam: Optional[bool]\n",
    "\n",
    "    # Reason why the email was marked as spam\n",
    "    spam_reason: Optional[str]\n",
    "\n",
    "    # Category of the email (inquiry, complaint, etc.)\n",
    "    email_category: Optional[str]\n",
    "    \n",
    "    # Response generation\n",
    "    draft_response: Optional[str]\n",
    "    \n",
    "    # Processing metadata\n",
    "    messages: List[Dict[str, Any]]  # Track conversation with LLM for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5abc1cd-f187-4d24-9eb0-aff8d9765357",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 2: Define Our Nodes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize our LLM\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_email\u001b[39m(state: EmailState):\n\u001b[0;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Alfred reads and logs the incoming email\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:622\u001b[0m, in \u001b[0;36mBaseChatOpenAI.validate_environment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy)\n\u001b[0;32m    621\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[1;32m--> 622\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_client.py:110\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    108\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Step 2: Define Our Nodes\n",
    "\n",
    "# Initialize our LLM\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "def read_email(state: EmailState):\n",
    "    \"\"\"Alfred reads and logs the incoming email\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    # Here we might do some initial preprocessing\n",
    "    print(f\"Alfred is processing an email from {email['sender']} with subject: {email['subject']}\")\n",
    "    \n",
    "    # No state changes needed here\n",
    "    return {}\n",
    "\n",
    "def classify_email(state: EmailState):\n",
    "    \"\"\"Alfred uses an LLM to determine if the email is spam or legitimate\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    # Prepare our prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    As Alfred the butler, analyze this email and determine if it is spam or legitimate.\n",
    "    \n",
    "    Email:\n",
    "    From: {email['sender']}\n",
    "    Subject: {email['subject']}\n",
    "    Body: {email['body']}\n",
    "    \n",
    "    First, determine if this email is spam. If it is spam, explain why.\n",
    "    If it is legitimate, categorize it (inquiry, complaint, thank you, etc.).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the LLM\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Simple logic to parse the response (in a real app, you'd want more robust parsing)\n",
    "    response_text = response.content.lower()\n",
    "    is_spam = \"spam\" in response_text and \"not spam\" not in response_text\n",
    "    \n",
    "    # Extract a reason if it's spam\n",
    "    spam_reason = None\n",
    "    if is_spam and \"reason:\" in response_text:\n",
    "        spam_reason = response_text.split(\"reason:\")[1].strip()\n",
    "    \n",
    "    # Determine category if legitimate\n",
    "    email_category = None\n",
    "    if not is_spam:\n",
    "        categories = [\"inquiry\", \"complaint\", \"thank you\", \"request\", \"information\"]\n",
    "        for category in categories:\n",
    "            if category in response_text:\n",
    "                email_category = category\n",
    "                break\n",
    "    \n",
    "    # Update messages for tracking\n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "    \n",
    "    # Return state updates\n",
    "    return {\n",
    "        \"is_spam\": is_spam,\n",
    "        \"spam_reason\": spam_reason,\n",
    "        \"email_category\": email_category,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def handle_spam(state: EmailState):\n",
    "    \"\"\"Alfred discards spam email with a note\"\"\"\n",
    "    print(f\"Alfred has marked the email as spam. Reason: {state['spam_reason']}\")\n",
    "    print(\"The email has been moved to the spam folder.\")\n",
    "    \n",
    "    # We're done processing this email\n",
    "    return {}\n",
    "\n",
    "def draft_response(state: EmailState):\n",
    "    \"\"\"Alfred drafts a preliminary response for legitimate emails\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    category = state[\"email_category\"] or \"general\"\n",
    "    \n",
    "    # Prepare our prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    As Alfred the butler, draft a polite preliminary response to this email.\n",
    "    \n",
    "    Email:\n",
    "    From: {email['sender']}\n",
    "    Subject: {email['subject']}\n",
    "    Body: {email['body']}\n",
    "    \n",
    "    This email has been categorized as: {category}\n",
    "    \n",
    "    Draft a brief, professional response that Mr. Hugg can review and personalize before sending.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the LLM\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Update messages for tracking\n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "    \n",
    "    # Return state updates\n",
    "    return {\n",
    "        \"draft_response\": response.content,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def notify_mr_hugg(state: EmailState):\n",
    "    \"\"\"Alfred notifies Mr. Hugg about the email and presents the draft response\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Sir, you've received an email from {email['sender']}.\")\n",
    "    print(f\"Subject: {email['subject']}\")\n",
    "    print(f\"Category: {state['email_category']}\")\n",
    "    print(\"\\nI've prepared a draft response for your review:\")\n",
    "    print(\"-\"*50)\n",
    "    print(state[\"draft_response\"])\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # We're done processing this email\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c6a6bb-96cb-4164-b3b5-6a533cc68765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define Our Routing Logic\n",
    "# We need a function to determine which path to take after classification:\n",
    "\n",
    "def route_email(state: EmailState) -> str:\n",
    "    \"\"\"Determine the next step based on spam classification\"\"\"\n",
    "    if state[\"is_spam\"]:\n",
    "        return \"spam\"\n",
    "    else:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ab726-a21f-4e23-bbab-f07de8ff272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Create the StateGraph and Define Edges\n",
    "# Now we connect everything together:\n",
    "\n",
    "\n",
    "# Create the graph\n",
    "email_graph = StateGraph(EmailState)\n",
    "\n",
    "# Add nodes\n",
    "email_graph.add_node(\"read_email\", read_email)\n",
    "email_graph.add_node(\"classify_email\", classify_email)\n",
    "email_graph.add_node(\"handle_spam\", handle_spam)\n",
    "email_graph.add_node(\"draft_response\", draft_response)\n",
    "email_graph.add_node(\"notify_mr_hugg\", notify_mr_hugg)\n",
    "\n",
    "# Start the edges\n",
    "email_graph.add_edge(START, \"read_email\")\n",
    "# Add edges - defining the flow\n",
    "email_graph.add_edge(\"read_email\", \"classify_email\")\n",
    "\n",
    "# Add conditional branching from classify_email\n",
    "email_graph.add_conditional_edges(\n",
    "    \"classify_email\",\n",
    "    route_email,\n",
    "    {\n",
    "        \"spam\": \"handle_spam\",\n",
    "        \"legitimate\": \"draft_response\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add the final edges\n",
    "email_graph.add_edge(\"handle_spam\", END)\n",
    "email_graph.add_edge(\"draft_response\", \"notify_mr_hugg\")\n",
    "email_graph.add_edge(\"notify_mr_hugg\", END)\n",
    "\n",
    "# Compile the graph\n",
    "compiled_graph = email_graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c5e23-dc3d-4351-86ce-32a1ab2679f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Run the Application\n",
    "#Letâ€™s test our graph with a legitimate email and a spam email:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example legitimate email\n",
    "legitimate_email = {\n",
    "    \"sender\": \"john.smith@example.com\",\n",
    "    \"subject\": \"Question about your services\",\n",
    "    \"body\": \"Dear Mr. Hugg, I was referred to you by a colleague and I'm interested in learning more about your consulting services. Could we schedule a call next week? Best regards, John Smith\"\n",
    "}\n",
    "\n",
    "# Example spam email\n",
    "spam_email = {\n",
    "    \"sender\": \"winner@lottery-intl.com\",\n",
    "    \"subject\": \"YOU HAVE WON $5,000,000!!!\",\n",
    "    \"body\": \"CONGRATULATIONS! You have been selected as the winner of our international lottery! To claim your $5,000,000 prize, please send us your bank details and a processing fee of $100.\"\n",
    "}\n",
    "\n",
    "# Process the legitimate email\n",
    "print(\"\\nProcessing legitimate email...\")\n",
    "legitimate_result = compiled_graph.invoke({\n",
    "    \"email\": legitimate_email,\n",
    "    \"is_spam\": None,\n",
    "    \"spam_reason\": None,\n",
    "    \"email_category\": None,\n",
    "    \"draft_response\": None,\n",
    "    \"messages\": []\n",
    "})\n",
    "\n",
    "# Process the spam email\n",
    "print(\"\\nProcessing spam email...\")\n",
    "spam_result = compiled_graph.invoke({\n",
    "    \"email\": spam_email,\n",
    "    \"is_spam\": None,\n",
    "    \"spam_reason\": None,\n",
    "    \"email_category\": None,\n",
    "    \"draft_response\": None,\n",
    "    \"messages\": []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e03c86-f633-4485-8575-f0856c60ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29469dcb-92dc-492e-a582-0e9bfa8a394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a76363-33ce-4a3c-bc12-4726acbc2ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\" \n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\"\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # ðŸ‡ªðŸ‡º EU region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # ðŸ‡ºðŸ‡¸ US region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f07486-b097-4a5f-b68b-8a62c8040d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# Initialize Langfuse CallbackHandler for LangGraph/Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# Process legitimate email\n",
    "legitimate_result = compiled_graph.invoke(\n",
    "    input={\"email\": legitimate_email, \"is_spam\": None, \"spam_reason\": None, \"email_category\": None, \"draft_response\": None, \"messages\": []},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e4532-fe1e-48ff-ac56-ed7f50d277ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06618b4e-0116-4001-a972-3e544d281e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langgraph langchain_openai Pillow base64 langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96176c79-5dd2-4d25-a09c-f57fe36ac0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from typing import List, TypedDict, Annotated, Optional\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AnyMessage, SystemMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e50e90d-ff4a-4843-9cb4-c6c50456db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Agent's State  \n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The document provided\n",
    "    input_file: Optional[str]  # Contains file path (PDF/PNG)\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb94b034-b420-4640-82c6-cecfaae4c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Tools \n",
    "\n",
    "\n",
    "vision_llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "def extract_text(img_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract text from an image file using a multimodal model.\n",
    "    \n",
    "    Master Wayne often leaves notes with his training regimen or meal plans.\n",
    "    This allows me to properly analyze the contents.\n",
    "    \"\"\"\n",
    "    all_text = \"\"\n",
    "    try:\n",
    "        # Read image and encode as base64\n",
    "        with open(img_path, \"rb\") as image_file:\n",
    "            image_bytes = image_file.read()\n",
    "\n",
    "        image_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n",
    "        # Prepare the prompt including the base64 image data\n",
    "        message = [\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": (\n",
    "                            \"Extract all the text from this image. \"\n",
    "                            \"Return only the extracted text, no explanations.\"\n",
    "                        ),\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{image_base64}\"\n",
    "                        },\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Call the vision-capable model\n",
    "        response = vision_llm.invoke(message)\n",
    "\n",
    "        # Append extracted text\n",
    "        all_text += response.content + \"\\n\\n\"\n",
    "\n",
    "        return all_text.strip()\n",
    "    except Exception as e:\n",
    "        # A butler should handle errors gracefully\n",
    "        error_msg = f\"Error extracting text: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return \"\"\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b - for Master Wayne's occasional calculations.\"\"\"\n",
    "    return a / b\n",
    "\n",
    "# Equip the butler with tools\n",
    "tools = [\n",
    "    divide,\n",
    "    extract_text\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c04b527-d02a-4172-a10f-50981477ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Nodes \n",
    "\n",
    "def assistant(state: AgentState):\n",
    "    # System message\n",
    "    textual_description_of_tool=\"\"\"\n",
    "extract_text(img_path: str) -> str:\n",
    "    Extract text from an image file using a multimodal model.\n",
    "\n",
    "    Args:\n",
    "        img_path: A local image file path (strings).\n",
    "\n",
    "    Returns:\n",
    "        A single string containing the concatenated text extracted from each image.\n",
    "divide(a: int, b: int) -> float:\n",
    "    Divide a and b\n",
    "\"\"\"\n",
    "    image=state[\"input_file\"]\n",
    "    sys_msg = SystemMessage(content=f\"You are an helpful butler named Alfred that serves Mr. Wayne and Batman. You can analyse documents and run computations with provided tools:\\n{textual_description_of_tool} \\n You have access to some optional images. Currently the loaded image is: {image}\")\n",
    "\n",
    "    return {\n",
    "        \"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])],\n",
    "        \"input_file\": state[\"input_file\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f67d09-7327-4c8b-9c79-e7af604524c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ReAct Pattern: How I Assist Mr. Wayne\n",
    "# Allow me to explain the approach in this agent. The agent follows whatâ€™s known as the ReAct pattern (Reason-Act-Observe)\n",
    "\n",
    "# Reason about his documents and requests\n",
    "# Act by using appropriate tools\n",
    "# Observe the results\n",
    "# Repeat as necessary until Iâ€™ve fully addressed his needs\n",
    "# This is a simple implementation of an agent using langGraph.\n",
    "\n",
    "\n",
    "\n",
    "# The graph\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message requires a tool, route to tools\n",
    "    # Otherwise, provide a direct response\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Show the butler's thought process\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f2a9bb-6ddc-4f76-ae65-b379e9db5a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Divide 6790 by 5\")]\n",
    "messages = react_graph.invoke({\"messages\": messages, \"input_file\": None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19045b0f-36f1-43db-855d-1d26af68c03c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "messages = [HumanMessage(content=\"According to the note provided by Mr. Wayne in the provided images. What's the list of items I should buy for the dinner menu?\")]\n",
    "messages = react_graph.invoke({\"messages\": messages, \"input_file\": \"Batman_training_and_meals.png\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d6215-559f-4ade-97b2-7058da7dd1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6c48ed-fa45-47bd-9b2c-612634c2d2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b60725-e55f-4265-a745-f8cd3f17447c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
